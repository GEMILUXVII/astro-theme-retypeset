---
title: '写在 ChatGPT 3.5 发布三周年：被折叠的时间'
published: '2025-11-30'
draft: false
tags: ['tech', 'ai', 'chatgpt', 'singularity']
---

### 引言：时间感的丧失

今天是 2025 年 11 月 30 日，三年前，OpenAI 发布了 ChatGPT 3.5。

三年，我们就从 GPT-3.5 跨越到了如今的推理模型。这是不可想象的进步。技术发展的速度快得已经让我们丧失了对时间的敏感。

作为工科出身的人，我对好的、能提高效率的工具向来是持积极态度的。以前我或许会避讳“依赖”这个词，强调人的主体性，但现在我不得不诚实地说：**我对 AI 产生了依赖，且并不为此感到羞愧。**

### 现状：与概率共存

这种依赖并非盲目，而是建立在一个清醒的技术认知之上：目前的生成式 AI，无论表现得多么智能，本质上依然是基于 **Next Token Prediction（下一个词预测）** 的概率模型。

很多人好奇：“为什么 AI 写代码时偶尔会虚构不存在的库函数？”原因很简单，它并没有人类那样的全局架构思想。它写代码并非先构思蓝图再填充细节，而是在计算：在当前语境下，下一个字符出现概率最高的是谁。

但正是这种架构，带来了旧模型无法比拟的优势。所有的 Token 都坐在桌边。模型不需要按顺序记忆，通过计算权重，它可以瞬间“看到”几千字之前的某个变量定义。

### 未来：相互叠加的 S 型曲线

站在三周年的节点向后看，我认为 AI 的发展不会是一条单调的直线，而更像是一系列相互叠加、彼此推动的 **S 型曲线**，未来大致可分为三个阶段：

#### 1. 短期 (1-3 年)：代理化与小型化

这是**实用化与民主化**的阶段。AI 将从昂贵的云端大模型向更高效的端侧小模型下沉。

- **AI Agents 的完备**：AI 将会变为三头六臂之器物，不再止于坐而论道。
- **模型的小型化**：并不是所有任务都需要动辄几千亿参数的巨型模型。未来我们将看到更多针对特定方向微调的小型模型，它们可以毫无阻碍运行在自己的设备上，近期刚开源的阿里千问生图模型 **`Z-Image`** 就是一个很好的例子，其仅用 6B 参数就能达到很好的生成效果。

::github{repo="Tongyi-MAI/Z-Image"}

#### 2. 中期 (3-10 年)：架构突破

这是**深层推理与架构重构**的阶段。当前的技术栈将面临物理瓶颈的挑战。

- **超越 Transformer**：当前的 Transformer 架构依赖于注意力机制，其计算复杂度随上下文长度呈二次方增长 ($O(n^2)$)。新的架构（如状态空间模型 Mamba）可能会取代现有的 Transformer。

#### 3. 长期 (10 年以上)：科学探索与后摩尔计算

这是**自主发现与算力跃迁**的阶段。AI 的发展将倒逼底层硬件的革命。

- **后摩尔定律计算**：传统的冯·诺依曼架构和 GPU 正逼近物理极限，这就要求硬件必须摆脱通用计算的束缚，例如新型计算方式来实现更高的计算效率。

### 结语

有人说 20 年后我们会领先现在的宇宙一个身位，我不知道那么远的事情。我只知道，这三年时间，足以让一项技术从陌生变得不可或缺。

如果过去的三年是某种预兆，那么所谓的“瓶颈”或许只是我们的想象罢了。
